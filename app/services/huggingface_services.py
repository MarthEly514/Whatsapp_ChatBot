"""
Service pour interagir avec l'API Hugging Face
G√®re la g√©n√©ration de texte avec les mod√®les de langage
"""

import requests
import time
from typing import Optional, Dict, Any
from app.config import Config
from app.utils.logger import setup_logger

logger = setup_logger(__name__)


class HuggingFaceService:
    """Service pour g√©rer les interactions avec Hugging Face"""
    
    def __init__(self):
        """Initialise le service Hugging Face"""
        self.api_key = Config.HUGGINGFACE_API_KEY
        self.model = Config.HUGGINGFACE_MODEL
        self.api_url = Config.HUGGINGFACE_API_URL
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        self.generation_params = Config.get_huggingface_params()
        
        logger.info(f"Service Hugging Face initialis√© avec mod√®le: {self.model}")
    
    def generate_response(
        self,
        prompt: str,
        user_name: str = "User",
        max_retries: int = 3
    ) -> str:
        """
        G√©n√®re une r√©ponse √† partir d'un prompt
        
        Args:
            prompt: Texte du message utilisateur
            user_name: Nom de l'utilisateur
            max_retries: Nombre de tentatives en cas d'erreur
            
        Returns:
            R√©ponse g√©n√©r√©e par le mod√®le
        """
        # Construire le prompt avec contexte
        formatted_prompt = self._format_prompt(prompt, user_name)
        
        payload = {
            "inputs": formatted_prompt,
            "parameters": self.generation_params
        }
        
        for attempt in range(max_retries):
            try:
                logger.info(f"G√©n√©ration de r√©ponse (tentative {attempt + 1}/{max_retries})")
                logger.debug(f"Prompt: {formatted_prompt[:100]}...")
                
                response = requests.post(
                    self.api_url,
                    headers=self.headers,
                    json=payload,
                    timeout=60
                )
                
                # G√©rer les cas sp√©cifiques
                if response.status_code == 503:
                    # Mod√®le en cours de chargement
                    logger.warning("Mod√®le en cours de chargement, attente...")
                    estimated_time = response.json().get('estimated_time', 20)
                    time.sleep(min(estimated_time, 30))
                    continue
                
                response.raise_for_status()
                result = response.json()
                
                # Extraire la r√©ponse
                generated_text = self._extract_response(result)
                
                if generated_text:
                    logger.info(f"R√©ponse g√©n√©r√©e avec succ√®s: {generated_text[:100]}...")
                    return generated_text
                else:
                    logger.warning("R√©ponse vide du mod√®le")
                    if attempt < max_retries - 1:
                        time.sleep(2)
                        continue
                
            except requests.exceptions.Timeout:
                logger.error(f"Timeout lors de la requ√™te (tentative {attempt + 1})")
                if attempt < max_retries - 1:
                    time.sleep(5)
                    continue
                    
            except requests.exceptions.RequestException as e:
                logger.error(f"Erreur API Hugging Face: {e}")
                if hasattr(e, 'response') and e.response is not None:
                    logger.error(f"R√©ponse: {e.response.text}")
                if attempt < max_retries - 1:
                    time.sleep(5)
                    continue
                    
            except Exception as e:
                logger.error(f"Erreur inattendue: {e}", exc_info=True)
                if attempt < max_retries - 1:
                    time.sleep(5)
                    continue
        
        # Si toutes les tentatives √©chouent
        return self._get_fallback_response()
    
    def _format_prompt(self, message: str, user_name: str) -> str:
        """
        Formate le prompt selon le mod√®le utilis√©
        
        Args:
            message: Message de l'utilisateur
            user_name: Nom de l'utilisateur
            
        Returns:
            Prompt format√©
        """
        # D√©tection du type de mod√®le pour adapter le format
        model_lower = self.model.lower()
        
        if 'mistral' in model_lower or 'mixtral' in model_lower:
            # Format Mistral avec [INST]
            return f"""[INST] Tu es un assistant WhatsApp utile et amical.
R√©ponds de mani√®re concise et naturelle en 2-3 phrases maximum.

{user_name} te demande: {message} [/INST]"""
        
        elif 'llama' in model_lower:
            # Format Llama 2
            return f"""<s>[INST] <<SYS>>
Tu es un assistant WhatsApp utile et amical.
R√©ponds de mani√®re concise et naturelle en 2-3 phrases maximum.
<</SYS>>

{user_name} te demande: {message} [/INST]"""
        
        elif 'flan' in model_lower:
            # Format Flan-T5 (simple)
            return f"R√©ponds √† cette question de mani√®re concise: {message}"
        
        else:
            # Format g√©n√©rique
            return f"""Assistant: Tu es un assistant WhatsApp.
User ({user_name}): {message}
Assistant:"""
    
    def _extract_response(self, api_response: Any) -> Optional[str]:
        """
        Extrait le texte g√©n√©r√© de la r√©ponse API
        
        Args:
            api_response: R√©ponse de l'API Hugging Face
            
        Returns:
            Texte g√©n√©r√© ou None
        """
        try:
            if isinstance(api_response, list) and len(api_response) > 0:
                # Format standard: [{"generated_text": "..."}]
                if isinstance(api_response[0], dict):
                    generated = api_response[0].get('generated_text', '')
                    
                    # Nettoyer la r√©ponse (enlever le prompt si pr√©sent)
                    if '[/INST]' in generated:
                        generated = generated.split('[/INST]')[-1].strip()
                    elif 'Assistant:' in generated:
                        parts = generated.split('Assistant:')
                        generated = parts[-1].strip() if len(parts) > 1 else generated
                    
                    return generated.strip()
                else:
                    return str(api_response[0]).strip()
            
            elif isinstance(api_response, dict):
                # Autre format possible
                return api_response.get('generated_text', '').strip()
            
            return None
            
        except Exception as e:
            logger.error(f"Erreur lors de l'extraction de la r√©ponse: {e}")
            return None
    
    def _get_fallback_response(self) -> str:
        """
        Retourne une r√©ponse de secours en cas d'erreur
        
        Returns:
            Message de secours
        """
        return (
            "D√©sol√©, je rencontre actuellement un probl√®me technique. "
            "Veuillez r√©essayer dans quelques instants. üôè"
        )
    
    def check_model_status(self) -> Dict[str, Any]:
        """
        V√©rifie le statut du mod√®le
        
        Returns:
            Dict avec les infos du mod√®le
        """
        try:
            response = requests.get(
                self.api_url,
                headers=self.headers,
                timeout=10
            )
            
            return {
                "status": response.status_code,
                "available": response.status_code == 200,
                "message": response.text if response.status_code != 200 else "OK"
            }
            
        except Exception as e:
            logger.error(f"Erreur lors de la v√©rification du mod√®le: {e}")
            return {
                "status": 0,
                "available": False,
                "message": str(e)
            }